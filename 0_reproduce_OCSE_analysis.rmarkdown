---
title: "Results in Uto et al paper"
format: 
  html:
    embed-resources: true
    self-contained-math: true
    html-math-method: katex
editor: source
---



Here we reproduce the model in Uto et al. using nimble. 

I will use the notation in the paper. 

Consider $N$ examinees who are independently assessed on multiple $I$ items by multiple $R$ raters. Each examinee is rated by a subset of raters $\mathcal{R}_j$, with cardinality $|\mathcal{R}_j|\leq R$, on the same set of items $i=1,\dots, I$.
We let $\mathcal{J}_r = \{ j: r \in \mathcal{R}_j\}$ be the set of subjects scored by rater $r=1,\dots, R$. Let $Y_{jir}$ for $j=1,\dots,J$, $r \in \mathcal{R}_j$ and $i=1,\dots,I$ be a categorical random variable recording the examinee $j$'s score given by rater $r$ to item $i$. We consider, without loss of generality, that $Y_{jir} \in \{0, 1, \ldots, K\}$, for $i=1.\dots, I$, that is, all items comprise the same range of ordered categorical values. We further assume that the items measure a unidimensional construct modelled by a subject-specific latent trait $\theta_j \in \mathbb{R}$.  

The model in Uto et al has the following form: 

\begin{equation}
\mathbb{P}[Y_{jir}=k|Y_{jir} \in \{k,k-1\},\theta_j, \phi_{ir}, \delta_{irk}]= 
\frac{exp\{D* \phi_{ir}(\theta_j - \delta_{irk})\}}{1+exp\{D* \phi_{ir}(\theta_j - \delta_{irk})\}}  
\end{equation}

for $k=1,\dots, K;$ $j=1,\dots, N;$ $i=1,\dots, I$ and $r \in \mathcal{R}_j$.

The scale term is decomposed as 
\begin{equation}
 \phi_{ir} = \alpha_{i} \alpha_{r}
\end{equation}
where $\alpha_{i}$ represents the discriminatory power of item $i$, $\alpha_{r}$  represents the consistency of rater $r$.

In the location part, the novely is that the model considers a raterâ€“item interaction parameter representing the rater severity for valuation item ($\beta_{ir}$) and an item-specific step-difficulty parameter representing the difference
in rating scales among evaluation items ($d_{rm}$).

\begin{equation}
  \delta_{irk} = \beta_{ir} + d_{im} + d_{rm}
\end{equation}


**Note**: In the paper the term in the exponential is multiplied by $D = 1.7$ which is the scaling constant used to minimize the difference between the normal and logistic distribution functions.

### Constraints

Scale.  $\sum_{r = 1}^R \log \alpha_r = 0$

Location. 

  - $d_{r1} = 0$; $\sum_{k = 2}^K d_{rk} = 0$

  - $d_{i1} = 0$; $\sum_{k = 2}^K d_{ik} = 0$
  

### Results

Using 10,000 mcmc iteration with a burn-in of 4,000. 



```{r}
#| echo: false 

args <- list(resFileName = "output/OSCE_Long/para/para_uto.rds")

listLength <- length(strsplit(args$resFileName, "\\/|.rds")[[1]])
data <- strsplit(args$resFileName, "\\/|.rds")[[1]][listLength -2]
fileName <- strsplit(args$resFileName, "\\/|.rds")[[1]][listLength]

## modelType - parametric or semi
modelType <- strsplit(basename(fileName), "\\_|.rds")[[1]][1]

## read objects
resObj <- readRDS(args$resFileName)
samples <- resObj$samples

```





**Estimates fron nimble**



```{r}
alpha_r <- samples[, grep("^trans_alpha_r", colnames(samples))] |> colMeans()

## apply constraints on the posterior means for the scaling
get_prod_restricted_prm <- function(d){
  return(append(1.0/prod(d), d))
}
alpha_r<- get_prod_restricted_prm(alpha_r[2:5])


#######
d_rk <- samples[, grep("^category_est_r", colnames(samples))] |> colMeans() |> matrix(nrow = 5)

beta_ir <- samples[, grep("^beta_ir", colnames(samples))] |> colMeans() 

severity <- beta_ir |> matrix(nrow = 30, byrow = FALSE) |> colMeans()


tab <- data.frame("alpha_r" = alpha_r, 
                  "d_{r1}" = d_rk[, 1], 
                  "d_{r2}" = d_rk[, 2], 
                  "d_{r3}" = d_rk[, 3], 
                  "d_{r4}" = d_rk[, 4], 
                  "severity" = severity,
                  row.names = NULL)

knitr::kable(tab, col.names = c("$\\alpha_r$", "$d_{r1}$", 
                                "$d_{r2}$", "$d_{r3}$", 
                                "$d_{r4}$", "severity"))
```



![paper_results](uto_et_al/uto_paper_rater_parameters.png)

Note: the difference is in that in the paper they apply the constraint on the posterior means; not sure if this is necessary. 



```{r}
```



**Posterior distribution of the latent trait**



```{r}

hist(samples[, grep("^eta", colnames(samples))], 
	breaks = 20, prob= TRUE, ylim = c(0,1), 
	main = "Posterior distribution of the latent trait", 
	xlab = "Latent trait")
lines(density(samples[, grep("^eta", colnames(samples))]), col = 4, lwd = 2)


alpha_i <- samples[, grep("^alpha_i", colnames(samples))] |> colMeans()

```



### Semiparametric version

Identical model, but using a DP mixture for the latent ability



```{r}
#| echo: false 

args <- list(resFileName = "output/OSCE_Long/semi/semi_uto.rds")

listLength <- length(strsplit(args$resFileName, "\\/|.rds")[[1]])
data <- strsplit(args$resFileName, "\\/|.rds")[[1]][listLength -2]
fileName <- strsplit(args$resFileName, "\\/|.rds")[[1]][listLength]

## modelType - parametric or semi
modelType <- strsplit(basename(fileName), "\\_|.rds")[[1]][1]

## read objects
resObj <- readRDS(args$resFileName)
samples <- resObj$samples

```





**Estimates fron nimble**



```{r}
alpha_r <- samples[, grep("^trans_alpha_r", colnames(samples))] |> colMeans()

## apply constraints on the posterior means for the scaling
get_prod_restricted_prm <- function(d){
  return(append(1.0/prod(d), d))
}
alpha_r<- get_prod_restricted_prm(alpha_r[2:5])


#######
d_rk <- samples[, grep("^category_est_r", colnames(samples))] |> colMeans() |> matrix(nrow = 5)

beta_ir <- samples[, grep("^beta_ir", colnames(samples))] |> colMeans() 

severity <- beta_ir |> matrix(nrow = 30, byrow = FALSE) |> colMeans()


tab <- data.frame("alpha_r" = alpha_r, 
                  "d_{r1}" = d_rk[, 1], 
                  "d_{r2}" = d_rk[, 2], 
                  "d_{r3}" = d_rk[, 3], 
                  "d_{r4}" = d_rk[, 4], 
                  "severity" = severity,
                  row.names = NULL)

knitr::kable(tab, col.names = c("$\\alpha_r$", "$d_{r1}$", 
                                "$d_{r2}$", "$d_{r3}$", 
                                "$d_{r4}$", "severity"))
```

```{r}
source("functions/estimateDPdensity.R")

hist(samples[, grep("^eta", colnames(samples))], 
	breaks = 20, prob= TRUE, ylim = c(0,1), 
	main = "Posterior distribution of the latent trait", 
	xlab = "Latent trait")
lines(density(samples[, grep("^eta", colnames(samples))]), col = 4, lwd = 2)


out <- estimateDPdensity(samples, 
                         paramNames = list(alpha = "alpha_dp", 
                                          muTilde = "muTilde", 
                                          s2Tilde = "s2Tilde", 
                                          zi = "zi"), 
                         nIndividuals = 30, 
	grid = seq(-2, 2, length = 200))

res <- data.frame(grid = out$grid, mean = apply(out$densitySamples, 2, mean))

library(ggplot2)

ggplot(res, aes(x=grid, y = mean)) + geom_line()

```
